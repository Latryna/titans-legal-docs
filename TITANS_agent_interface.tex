\documentclass[letterpaper,twocolumn]{article}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}

\begin{document}

\title{TITANS Agent Interface Specification}
\maketitle

\section{Overview}

The TITANS agent exposes a simple REST interface so that external systems can interact with its cognitive architecture.  The interface has been designed to support episodic memory (Milestone~2) and semantic reasoning (Milestones~4–5), while remaining flexible enough to incorporate additional modules in the future.

\section{Endpoints}

\begin{description}
\item[\texttt{/chat} (POST)] Accepts a JSON message containing the user’s utterance and returns a response generated by the agent.  Internally, the agent uses its episodic and semantic memories to ground the reply and ensure continuity across turns.

\item[\texttt{/graph} (GET)] Returns the current semantic knowledge graph as a list of nodes and edges.  This representation captures entities and relations derived from the agent’s experience.

\item[\texttt{/memory} (GET / POST)] Provides access to the memory stores.  A \texttt{GET} request retrieves stored episodes or concepts; a \texttt{POST} request inserts a new memory item.  The `type` field selects between episodic and semantic memory.
\end{description}

\section{Memory Structure}

The episodic memory stores timestamped sequences of perceptions and actions (as defined in Section~5 of the project documentation).  Each episode records the sensory input, internal state and executed actions.  The semantic memory abstracts over episodes to form general concepts and relations (Section~7).  Each memory item is assigned a unique identifier, timestamp and optional metadata such as source and confidence.

\section{Integration}

These endpoints should be accessed via the workspace API defined in the accompanying specification.  External LLMs can call the \texttt{/chat} endpoint to enrich their responses with grounded information from the TITANS agent.  The agent’s REST service runs locally and can be proxied through OpenRouter to allow remote models (e.g. GPT‑4, Claude) or local LM Studio models to participate in the dialogue.

\end{document}